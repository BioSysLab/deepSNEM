{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader, Dataset\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from models.graph_transformer.euclidean_graph_transformer import GraphTransformerEncoder\n",
    "from models.graph_transformer.autoencoder_base import DeepSNEM, LinearDecoder, FermiDiracDecoder\n",
    "from utils.data_gen import SNLDataset, load_prot_embs, wcsv2graph, load_prot_embs_go\n",
    "\n",
    "import re\n",
    "import gc\n",
    "\n",
    "from captum.attr import IntegratedGradients,InterpretableEmbeddingBase\n",
    "from captum.attr import visualization, configure_interpretable_embedding_layer,remove_interpretable_embedding_layer\n",
    "\n",
    "dev = torch.device('cuda')\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prots = 'data/prot_embeddings/new_features/proteins.csv'\n",
    "unique_df = pd.read_csv(unique_prots)\n",
    "global_dict = {}\n",
    "\n",
    "for idx, prot in enumerate(unique_df.proteins.to_numpy()):\n",
    "    global_dict[prot] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_fnames = '../snac_data/file_info_weighted.csv'\n",
    "w_fnames = pd.read_csv(weighted_fnames)\n",
    "w_path_list = w_fnames.files_weighted.to_numpy()\n",
    "wsample = w_path_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(acts=[68, 2], edge_index=[2, 83], global_idx=[68], label=[1], neg_childs=[68], pos_childs=[68], seq_mat=[68, 68], sign=[83, 2], weight=[83], y=[3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = wcsv2graph(wsample, global_dict, [0,0,1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIZE = 512\n",
    "EMB_DIM = 512\n",
    "prot_embs = load_prot_embs_go(SIZE, norm=False)\n",
    "summarizer = lambda z, *args, **kwargs: z.mean(dim=0)\n",
    "encoder = GraphTransformerEncoder(n_layers=1, n_heads=4, n_hid=EMB_DIM, pretrained_weights=prot_embs[0], \n",
    "                                  summarizer=summarizer).to(dev)\n",
    "decoder = FermiDiracDecoder(1.0).to(dev)\n",
    "autoenc = DeepSNEM(encoder, decoder).to(dev)\n",
    "autoenc.load_state_dict(torch.load('embeddings/autoencoder_graph/gt_512_tl_1_lp.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5638,  1.7662, -1.2303,  ...,  0.3325, -0.2374,  0.0486],\n",
       "        [-0.9060,  1.8102,  1.4526,  ..., -0.1316,  0.1973,  0.2973],\n",
       "        [-0.9025, -0.6047, -1.1277,  ..., -0.1601,  0.2491,  0.1278],\n",
       "        ...,\n",
       "        [-0.7644, -0.5591, -1.1038,  ...,  0.2015,  0.2613,  0.2287],\n",
       "        [-0.7576, -0.5490,  0.8497,  ..., -0.3825, -0.0021,  0.1408],\n",
       "        [-0.7599, -0.5567, -1.3666,  ..., -0.0693,  0.3519,  0.0655]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoenc.encoder.emb_layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretable_embedding = configure_interpretable_embedding_layer(autoenc, 'encoder.emb_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = IntegratedGradients(autoenc)\n",
    "input_embedding = interpretable_embedding.indices_to_embeddings(data.global_idx.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('torch': conda)",
   "language": "python",
   "name": "python37164bittorchconda400f3b5524f54409b045df0fcc1fa418"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
