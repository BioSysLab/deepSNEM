{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
=======
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
<<<<<<< HEAD
    "import json\n",
    "sys.path.append('..')\n",
    "from custom_layers_tensorflow.tied_dense import DenseTied\n",
    "from keras.layers import Dense, Activation, Input, Layer, InputSpec, Embedding, Reshape, Dropout\n",
    "from keras.layers import Lambda, concatenate, BatchNormalization, PReLU\n",
=======
    "sys.path.append('..')\n",
    "from custom_layers_tensorflow.tied_dense import DenseTied\n",
    "from keras.layers import Dense, Activation, Input, Layer, InputSpec, Embedding, Reshape\n",
    "from keras.layers import Lambda, concatenate\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
    "from keras.losses import binary_crossentropy, mse\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import initializers, activations, regularizers, constraints\n",
    "from keras.constraints import UnitNorm\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import ast\n",
<<<<<<< HEAD
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from collections import defaultdict\n",
    "\n",
    "import umap"
=======
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from collections import defaultdict"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_emb = '../data/proteins_sorted_embedded.csv'\n",
    "df = pd.read_csv(prot_emb)\n",
    "seq_emb = df['seq_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequ = []\n",
    "for seq in seq_emb:\n",
    "    sequ.append(ast.literal_eval(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03324135,  0.10667547, -0.01521349, ..., -0.04834097,\n",
       "         0.03296835, -0.18079177],\n",
       "       [-0.00365548,  0.07138977, -0.16177309, ..., -0.12891184,\n",
       "        -0.01673795, -0.4157664 ],\n",
       "       [ 0.03429634,  0.09304613, -0.06330083, ..., -0.04096478,\n",
       "        -0.06731319,  0.03703454],\n",
       "       ...,\n",
       "       [ 0.13704471,  0.05224798, -0.21351333, ..., -0.21883018,\n",
       "         0.06400761, -0.4060422 ],\n",
       "       [-0.01278233,  0.01587907, -0.19893803, ..., -0.1997465 ,\n",
       "         0.02866214, -0.27838326],\n",
       "       [-0.04970011,  0.10989428, -0.12965776, ..., -0.08165135,\n",
       "         0.00405658, -0.16662924]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = np.array(sequ)\n",
<<<<<<< HEAD
    "#scaler = MinMaxScaler()\n",
    "#sequences = scaler.fit_transform(sequences)\n",
=======
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Tied Autoencoder"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 230,
=======
   "execution_count": 5,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
=======
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prot_embs (InputLayer)       (None, 1024)              0         \n",
      "_________________________________________________________________\n",
<<<<<<< HEAD
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "enc_1 (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 128)               128       \n",
      "_________________________________________________________________\n",
      "dec_2 (Dense)                (None, 1024)              132096    \n",
      "=================================================================\n",
      "Total params: 267,520\n",
      "Trainable params: 265,472\n",
      "Non-trainable params: 2,048\n",
=======
      "enc_1 (Dense)                (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dec_2 (Dense)                (None, 1024)              132096    \n",
      "=================================================================\n",
      "Total params: 263,296\n",
      "Trainable params: 263,296\n",
      "Non-trainable params: 0\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(name='prot_embs', batch_shape=(None, 1024))\n",
    "\n",
<<<<<<< HEAD
    "enc = BatchNormalization(momentum=0.6)(inputs)\n",
    "enc = Dense(128, activation='linear', name='enc_1', kernel_constraint=UnitNorm(axis=0))(enc)\n",
    "enc = PReLU()(enc)\n",
    "\n",
    "dec = Dense(1024, activation='linear', name='dec_2', kernel_constraint=UnitNorm(axis=1))(enc)\n",
=======
    "enc = Dense(128, activation='linear', kernel_initializer='lecun_normal', name='enc_1', \n",
    "            kernel_constraint=UnitNorm(axis=0))(inputs)\n",
    "\n",
    "dec = Dense(1024, activation='linear', kernel_initializer='lecun_normal', \n",
    "            name='dec_2', kernel_constraint=UnitNorm(axis=1))(enc)\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
    "\n",
    "encoder = Model(inputs, enc)\n",
    "model = Model(inputs=[inputs], outputs=dec)\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, \n",
    "                    decay=0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss=['mse'], metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 231,
=======
   "execution_count": 6,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Train on 3231 samples, validate on 571 samples\n",
      "Epoch 1/300\n",
      "3231/3231 [==============================] - 1s 301us/step - loss: 0.0299 - mean_absolute_error: 0.1212 - val_loss: 0.0168 - val_mean_absolute_error: 0.0961\n",
      "Epoch 2/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0121 - mean_absolute_error: 0.0820 - val_loss: 0.0120 - val_mean_absolute_error: 0.0812\n",
      "Epoch 3/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0089 - mean_absolute_error: 0.0705 - val_loss: 0.0093 - val_mean_absolute_error: 0.0720\n",
      "Epoch 4/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0072 - mean_absolute_error: 0.0639 - val_loss: 0.0078 - val_mean_absolute_error: 0.0660\n",
      "Epoch 5/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0062 - mean_absolute_error: 0.0591 - val_loss: 0.0069 - val_mean_absolute_error: 0.0617\n",
      "Epoch 6/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0055 - mean_absolute_error: 0.0559 - val_loss: 0.0063 - val_mean_absolute_error: 0.0587\n",
      "Epoch 7/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0050 - mean_absolute_error: 0.0532 - val_loss: 0.0060 - val_mean_absolute_error: 0.0573\n",
      "Epoch 8/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0046 - mean_absolute_error: 0.0512 - val_loss: 0.0058 - val_mean_absolute_error: 0.0562\n",
      "Epoch 9/300\n",
      "3231/3231 [==============================] - 0s 29us/step - loss: 0.0043 - mean_absolute_error: 0.0494 - val_loss: 0.0052 - val_mean_absolute_error: 0.0530\n",
      "Epoch 10/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0040 - mean_absolute_error: 0.0480 - val_loss: 0.0050 - val_mean_absolute_error: 0.0519\n",
      "Epoch 11/300\n",
      "3231/3231 [==============================] - 0s 25us/step - loss: 0.0038 - mean_absolute_error: 0.0467 - val_loss: 0.0047 - val_mean_absolute_error: 0.0507\n",
      "Epoch 12/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0037 - mean_absolute_error: 0.0455 - val_loss: 0.0045 - val_mean_absolute_error: 0.0495\n",
      "Epoch 13/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0035 - mean_absolute_error: 0.0443 - val_loss: 0.0044 - val_mean_absolute_error: 0.0486\n",
      "Epoch 14/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0033 - mean_absolute_error: 0.0434 - val_loss: 0.0042 - val_mean_absolute_error: 0.0480\n",
      "Epoch 15/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0032 - mean_absolute_error: 0.0425 - val_loss: 0.0041 - val_mean_absolute_error: 0.0466\n",
      "Epoch 16/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0031 - mean_absolute_error: 0.0416 - val_loss: 0.0041 - val_mean_absolute_error: 0.0471\n",
      "Epoch 17/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0029 - mean_absolute_error: 0.0409 - val_loss: 0.0037 - val_mean_absolute_error: 0.0445\n",
      "Epoch 18/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0029 - mean_absolute_error: 0.0403 - val_loss: 0.0037 - val_mean_absolute_error: 0.0441\n",
      "Epoch 19/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0027 - mean_absolute_error: 0.0394 - val_loss: 0.0035 - val_mean_absolute_error: 0.0433\n",
      "Epoch 20/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0027 - mean_absolute_error: 0.0390 - val_loss: 0.0036 - val_mean_absolute_error: 0.0433\n",
      "Epoch 21/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0026 - mean_absolute_error: 0.0384 - val_loss: 0.0035 - val_mean_absolute_error: 0.0432\n",
      "Epoch 22/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0025 - mean_absolute_error: 0.0376 - val_loss: 0.0033 - val_mean_absolute_error: 0.0414\n",
      "Epoch 23/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0025 - mean_absolute_error: 0.0374 - val_loss: 0.0032 - val_mean_absolute_error: 0.0410\n",
      "Epoch 24/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0024 - mean_absolute_error: 0.0367 - val_loss: 0.0031 - val_mean_absolute_error: 0.0405\n",
      "Epoch 25/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0023 - mean_absolute_error: 0.0363 - val_loss: 0.0032 - val_mean_absolute_error: 0.0408\n",
      "Epoch 26/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0023 - mean_absolute_error: 0.0360 - val_loss: 0.0031 - val_mean_absolute_error: 0.0402\n",
      "Epoch 27/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0023 - mean_absolute_error: 0.0358 - val_loss: 0.0030 - val_mean_absolute_error: 0.0397\n",
      "Epoch 28/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0022 - mean_absolute_error: 0.0350 - val_loss: 0.0029 - val_mean_absolute_error: 0.0389\n",
      "Epoch 29/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0021 - mean_absolute_error: 0.0347 - val_loss: 0.0029 - val_mean_absolute_error: 0.0388\n",
      "Epoch 30/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0021 - mean_absolute_error: 0.0344 - val_loss: 0.0030 - val_mean_absolute_error: 0.0396\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 31/300\n",
      "3231/3231 [==============================] - 0s 29us/step - loss: 0.0020 - mean_absolute_error: 0.0337 - val_loss: 0.0027 - val_mean_absolute_error: 0.0373\n",
      "Epoch 32/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0019 - mean_absolute_error: 0.0330 - val_loss: 0.0027 - val_mean_absolute_error: 0.0372\n",
      "Epoch 33/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0019 - mean_absolute_error: 0.0326 - val_loss: 0.0026 - val_mean_absolute_error: 0.0364\n",
      "Epoch 34/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0018 - mean_absolute_error: 0.0323 - val_loss: 0.0027 - val_mean_absolute_error: 0.0375\n",
      "Epoch 35/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0018 - mean_absolute_error: 0.0322 - val_loss: 0.0026 - val_mean_absolute_error: 0.0366\n",
      "Epoch 36/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0018 - mean_absolute_error: 0.0321 - val_loss: 0.0026 - val_mean_absolute_error: 0.0365\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 37/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0018 - mean_absolute_error: 0.0317 - val_loss: 0.0024 - val_mean_absolute_error: 0.0355\n",
      "Epoch 38/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0017 - mean_absolute_error: 0.0314 - val_loss: 0.0026 - val_mean_absolute_error: 0.0361\n",
      "Epoch 39/300\n",
      "3231/3231 [==============================] - 0s 26us/step - loss: 0.0017 - mean_absolute_error: 0.0313 - val_loss: 0.0026 - val_mean_absolute_error: 0.0362\n",
      "Epoch 40/300\n",
      "3231/3231 [==============================] - 0s 29us/step - loss: 0.0017 - mean_absolute_error: 0.0312 - val_loss: 0.0025 - val_mean_absolute_error: 0.0358\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 41/300\n",
      "3231/3231 [==============================] - 0s 28us/step - loss: 0.0017 - mean_absolute_error: 0.0310 - val_loss: 0.0026 - val_mean_absolute_error: 0.0360\n",
      "Epoch 42/300\n",
      "3231/3231 [==============================] - 0s 27us/step - loss: 0.0017 - mean_absolute_error: 0.0309 - val_loss: 0.0025 - val_mean_absolute_error: 0.0359\n"
=======
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 3231 samples, validate on 571 samples\n",
      "Epoch 1/300\n",
      "3231/3231 [==============================] - 1s 268us/step - loss: 0.0074 - mean_absolute_error: 0.0615 - val_loss: 0.0035 - val_mean_absolute_error: 0.0446\n",
      "Epoch 2/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 0.0026 - mean_absolute_error: 0.0379 - val_loss: 0.0022 - val_mean_absolute_error: 0.0350\n",
      "Epoch 3/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 0.0018 - mean_absolute_error: 0.0316 - val_loss: 0.0018 - val_mean_absolute_error: 0.0308\n",
      "Epoch 4/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 0.0014 - mean_absolute_error: 0.0285 - val_loss: 0.0015 - val_mean_absolute_error: 0.0289\n",
      "Epoch 5/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 0.0013 - mean_absolute_error: 0.0265 - val_loss: 0.0014 - val_mean_absolute_error: 0.0273\n",
      "Epoch 6/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 0.0011 - mean_absolute_error: 0.0251 - val_loss: 0.0013 - val_mean_absolute_error: 0.0263\n",
      "Epoch 7/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 0.0010 - mean_absolute_error: 0.0242 - val_loss: 0.0012 - val_mean_absolute_error: 0.0255\n",
      "Epoch 8/300\n",
      "3231/3231 [==============================] - 0s 23us/step - loss: 9.7918e-04 - mean_absolute_error: 0.0234 - val_loss: 0.0012 - val_mean_absolute_error: 0.0250\n",
      "Epoch 9/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 9.2622e-04 - mean_absolute_error: 0.0228 - val_loss: 0.0011 - val_mean_absolute_error: 0.0243\n",
      "Epoch 10/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 8.9066e-04 - mean_absolute_error: 0.0224 - val_loss: 0.0011 - val_mean_absolute_error: 0.0241\n",
      "Epoch 11/300\n",
      "3231/3231 [==============================] - 0s 24us/step - loss: 8.6350e-04 - mean_absolute_error: 0.0220 - val_loss: 0.0011 - val_mean_absolute_error: 0.0238\n",
      "Epoch 12/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 8.4095e-04 - mean_absolute_error: 0.0217 - val_loss: 0.0010 - val_mean_absolute_error: 0.0237\n",
      "Epoch 13/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 8.3073e-04 - mean_absolute_error: 0.0216 - val_loss: 0.0010 - val_mean_absolute_error: 0.0237\n",
      "Epoch 14/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 8.4484e-04 - mean_absolute_error: 0.0218 - val_loss: 0.0010 - val_mean_absolute_error: 0.0237\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.003449999960139394.\n",
      "Epoch 15/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 7.8242e-04 - mean_absolute_error: 0.0210 - val_loss: 9.6692e-04 - val_mean_absolute_error: 0.0227\n",
      "Epoch 16/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 7.5324e-04 - mean_absolute_error: 0.0206 - val_loss: 9.6030e-04 - val_mean_absolute_error: 0.0226\n",
      "Epoch 17/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 7.4780e-04 - mean_absolute_error: 0.0205 - val_loss: 9.5001e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 18/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 7.4515e-04 - mean_absolute_error: 0.0205 - val_loss: 9.5221e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 19/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 7.4648e-04 - mean_absolute_error: 0.0205 - val_loss: 9.4731e-04 - val_mean_absolute_error: 0.0224\n",
      "Epoch 20/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 7.4315e-04 - mean_absolute_error: 0.0205 - val_loss: 9.4955e-04 - val_mean_absolute_error: 0.0225\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.001724999980069697.\n",
      "Epoch 21/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 7.1589e-04 - mean_absolute_error: 0.0201 - val_loss: 9.2384e-04 - val_mean_absolute_error: 0.0221\n",
      "Epoch 22/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 7.0795e-04 - mean_absolute_error: 0.0200 - val_loss: 9.1925e-04 - val_mean_absolute_error: 0.0220\n",
      "Epoch 23/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 7.0691e-04 - mean_absolute_error: 0.0199 - val_loss: 9.1679e-04 - val_mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0008624999900348485.\n",
      "Epoch 24/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.9456e-04 - mean_absolute_error: 0.0198 - val_loss: 9.0939e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 25/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.9218e-04 - mean_absolute_error: 0.0197 - val_loss: 9.0740e-04 - val_mean_absolute_error: 0.0219\n",
      "Epoch 26/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.9180e-04 - mean_absolute_error: 0.0197 - val_loss: 9.1008e-04 - val_mean_absolute_error: 0.0219\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0004312499950174242.\n",
      "Epoch 27/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.8505e-04 - mean_absolute_error: 0.0196 - val_loss: 9.0562e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 28/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.8351e-04 - mean_absolute_error: 0.0196 - val_loss: 9.0469e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 29/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.8276e-04 - mean_absolute_error: 0.0196 - val_loss: 9.0425e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002156249975087121.\n",
      "Epoch 30/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7937e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0346e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 31/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7888e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0339e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 32/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7862e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0352e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010781249875435606.\n",
      "Epoch 33/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7663e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0294e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 34/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7641e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0271e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 35/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7636e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0287e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 5.390624937717803e-05.\n",
      "Epoch 36/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7526e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0274e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 37/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7516e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0237e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 38/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7510e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0242e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.6953124688589014e-05.\n",
      "Epoch 39/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7457e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0223e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 40/300\n",
      "3231/3231 [==============================] - ETA: 0s - loss: 6.7393e-04 - mean_absolute_error: 0.019 - 0s 19us/step - loss: 6.7453e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0226e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7452e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0235e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.3476562344294507e-05.\n",
      "Epoch 42/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7422e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0228e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 43/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7420e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0222e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 44/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7420e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0221e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.7382811721472535e-06.\n",
      "Epoch 45/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7405e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0220e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 46/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7403e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0221e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 47/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7403e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0215e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.3691405860736268e-06.\n",
      "Epoch 48/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7395e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0214e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 49/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7394e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0215e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 50/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7394e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.6845702930368134e-06.\n",
      "Epoch 51/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7390e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 52/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7390e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 53/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7390e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 8.422851465184067e-07.\n",
      "Epoch 54/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7387e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0214e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 55/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7387e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 56/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7387e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.2114257325920335e-07.\n",
      "Epoch 57/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7386e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0213e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 58/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7386e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 59/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7386e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 2.1057128662960167e-07.\n",
      "Epoch 60/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 61/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 62/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0528564331480084e-07.\n",
      "Epoch 63/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 64/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 65/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 66/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 67/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 68/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 69/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 70/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 71/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 72/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 73/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 74/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 75/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 76/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 77/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 78/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 79/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 80/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 82/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 83/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 84/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 85/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0212e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 86/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 87/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 88/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 89/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7385e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 90/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 91/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 92/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 93/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 94/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 95/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 96/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 97/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 98/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 99/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 100/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 101/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 102/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 103/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 104/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 105/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 106/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 107/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 108/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 109/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 110/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 111/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0211e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 112/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 113/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 114/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 115/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 116/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 117/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 118/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7384e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 119/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 120/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 121/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 122/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 123/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 124/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 125/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 126/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 127/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 128/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 129/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 130/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0210e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 131/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 132/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 133/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 134/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 135/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 136/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 137/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 138/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7383e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 139/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 140/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 141/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 142/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 143/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 144/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 145/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 146/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 147/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 148/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 149/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0209e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 150/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 151/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 152/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 153/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 154/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 155/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7382e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 156/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 157/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 158/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 159/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 160/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 161/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 162/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0208e-04 - val_mean_absolute_error: 0.0218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 164/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 165/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 166/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 167/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 168/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 169/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7381e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 170/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 171/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 172/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 173/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00173: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 174/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0207e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 175/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 176/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 177/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 178/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 179/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 180/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 181/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7380e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 182/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 183/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 184/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 185/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 186/300\n",
      "3231/3231 [==============================] - 0s 23us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 187/300\n",
      "3231/3231 [==============================] - 0s 23us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0206e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 188/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00188: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 189/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 190/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 191/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 192/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 193/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7379e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 194/300\n",
      "3231/3231 [==============================] - 0s 23us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0205e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 195/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 196/300\n",
      "3231/3231 [==============================] - 0s 23us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 197/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 198/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 199/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 200/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00200: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 201/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 202/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 203/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7378e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00203: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 204/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 0s 17us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 205/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0204e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 206/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 207/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 208/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 209/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 210/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 211/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 212/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00212: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 213/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7377e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 214/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 215/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0203e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00215: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 216/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 217/300\n",
      "3231/3231 [==============================] - 0s 23us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 218/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00218: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 219/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 220/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 221/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 222/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7376e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 223/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 224/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 225/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0202e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 226/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 227/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00227: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 228/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 229/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 230/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00230: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 231/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 232/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7375e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 233/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0201e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00233: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 234/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 235/300\n",
      "3231/3231 [==============================] - 0s 17us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 236/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00236: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 237/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 238/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 239/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 240/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 241/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7374e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0200e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 242/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00242: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 243/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 244/300\n",
      "3231/3231 [==============================] - 0s 22us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00245: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 246/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 247/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 248/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00248: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 249/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7373e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 250/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0199e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 251/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00251: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 252/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 253/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 254/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 255/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 256/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 257/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7372e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00257: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 258/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 259/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0198e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 260/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0197e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 261/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0197e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 262/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0197e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 263/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0197e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00263: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 264/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0197e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 265/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0197e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 266/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7371e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 267/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 268/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 269/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 270/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 271/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 272/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00272: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 273/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0196e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 274/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7370e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0195e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 275/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0195e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00275: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 276/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0195e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 277/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0195e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 278/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0195e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00278: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 279/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 280/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 281/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00281: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 282/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7369e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 283/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 284/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 285/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0194e-04 - val_mean_absolute_error: 0.0218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 287/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 288/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 289/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 290/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7368e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00290: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 291/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 292/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0193e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 293/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00293: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 294/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 295/300\n",
      "3231/3231 [==============================] - 0s 18us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 296/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00296: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 297/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 298/300\n",
      "3231/3231 [==============================] - 0s 19us/step - loss: 6.7367e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 299/300\n",
      "3231/3231 [==============================] - 0s 21us/step - loss: 6.7366e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00299: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "Epoch 300/300\n",
      "3231/3231 [==============================] - 0s 20us/step - loss: 6.7366e-04 - mean_absolute_error: 0.0195 - val_loss: 9.0192e-04 - val_mean_absolute_error: 0.0218\n"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<keras.callbacks.History at 0x7f1e70b696d0>"
      ]
     },
     "execution_count": 231,
=======
       "<keras.callbacks.History at 0x7f72b8b87690>"
      ]
     },
     "execution_count": 6,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss',patience=5, min_delta=0)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss',factor=0.5, patience=3, verbose=1, min_lr=0.0000001)\n",
    "\n",
    "\n",
    "model.fit(sequences, sequences, epochs=300, batch_size=128, shuffle=True, validation_split=0.15, callbacks=[es, rlr])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 213,
=======
   "execution_count": 7,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = encoder.predict(sequences)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 214,
=======
   "execution_count": 8,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = model.predict(sequences)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03324135,  0.10667547, -0.01521349, ..., -0.04834097,\n",
       "        0.03296835, -0.18079177])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05561131,  0.1233272 , -0.08664784, ..., -0.05307619,\n",
       "        0.07628877, -0.20414567], dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
=======
   "execution_count": 9,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.029301616028083004"
      ]
     },
     "execution_count": 217,
=======
       "array([ 0.09193911,  0.01856159, -0.12037301, ..., -0.04668226,\n",
       "       -0.04119425, -0.07171778])"
      ]
     },
     "execution_count": 9,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "mean_absolute_error(sequences, reconstructed)"
=======
    "sequences[100]"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 218,
=======
   "execution_count": 10,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.039375380319925726"
      ]
     },
     "execution_count": 218,
=======
       "array([ 0.04256801, -0.00703095, -0.10061335, ..., -0.072161  ,\n",
       "       -0.01073783, -0.06864586], dtype=float32)"
      ]
     },
     "execution_count": 10,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "np.sqrt(mean_squared_error(sequences, reconstructed))"
=======
    "reconstructed[100]"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 223,
=======
   "execution_count": 11,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(embs)\n",
    "embs_df['embs'] = embs_df.apply(lambda r: tuple(r), axis=1).apply(np.array)\n",
    "df['seq_embs'] = embs_df.embs"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gene</th>\n",
       "      <th>seq_embedding</th>\n",
       "      <th>seq_embs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CREB1</td>\n",
       "      <td>[-0.033241346, 0.10667547, -0.015213485, 0.188...</td>\n",
       "      <td>[-0.0571773461997509, -0.03561268746852875, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SP1</td>\n",
       "      <td>[-0.0036554774, 0.07138977, -0.16177309, 0.191...</td>\n",
       "      <td>[-0.07485979795455933, -0.13472646474838257, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PPP3CA</td>\n",
       "      <td>[0.034296338, 0.09304613, -0.06330083, -0.0238...</td>\n",
       "      <td>[-0.08877427875995636, -0.2417590469121933, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>RCAN1</td>\n",
       "      <td>[-0.0005352832, -0.019785272, -0.019052623, 0....</td>\n",
       "      <td>[-0.04055699706077576, -0.11073018610477448, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PINK1</td>\n",
       "      <td>[0.12165684, 0.17958553, -0.043252468, 0.05135...</td>\n",
       "      <td>[-0.1586480289697647, 0.20324979722499847, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    gene                                      seq_embedding  \\\n",
       "0           1   CREB1  [-0.033241346, 0.10667547, -0.015213485, 0.188...   \n",
       "1           2     SP1  [-0.0036554774, 0.07138977, -0.16177309, 0.191...   \n",
       "2           3  PPP3CA  [0.034296338, 0.09304613, -0.06330083, -0.0238...   \n",
       "3           4   RCAN1  [-0.0005352832, -0.019785272, -0.019052623, 0....   \n",
       "4           5   PINK1  [0.12165684, 0.17958553, -0.043252468, 0.05135...   \n",
       "\n",
       "                                            seq_embs  \n",
       "0  [-0.0571773461997509, -0.03561268746852875, -0...  \n",
       "1  [-0.07485979795455933, -0.13472646474838257, -...  \n",
       "2  [-0.08877427875995636, -0.2417590469121933, -0...  \n",
       "3  [-0.04055699706077576, -0.11073018610477448, -...  \n",
       "4  [-0.1586480289697647, 0.20324979722499847, -0....  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
=======
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mf, bp, cc features encoding"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP / ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
=======
   "cell_type": "code",
   "execution_count": 12,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = '../data/mf_features.csv'\n",
<<<<<<< HEAD
    "mf_df = pd.read_csv(mf)\n",
    "mf = mf_df.drop('Unnamed: 0', axis=1)\n",
=======
    "mf = pd.read_csv(mf)\n",
    "mf = mf.drop('Unnamed: 0', axis=1)\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
    "mf = mf.apply(lambda r: tuple(r), axis=1).apply(np.array).to_list()\n",
    "mf = np.reshape(mf, (3802, 142))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": 13,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = '../data/bp_features.csv'\n",
<<<<<<< HEAD
    "bp_df = pd.read_csv(bp)\n",
    "bp = bp_df.drop('Unnamed: 0', axis=1)\n",
=======
    "bp = pd.read_csv(bp)\n",
    "bp = bp.drop('Unnamed: 0', axis=1)\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
    "bp = bp.apply(lambda r: tuple(r), axis=1).apply(np.array).to_list()\n",
    "bp = np.reshape(bp, (3802, 1039))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
=======
   "execution_count": 14,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = '../data/cc_features.csv'\n",
<<<<<<< HEAD
    "cc_df = pd.read_csv(cc)\n",
    "cc = cc_df.drop('Unnamed: 0', axis=1)\n",
=======
    "cc = pd.read_csv(cc)\n",
    "cc = cc.drop('Unnamed: 0', axis=1)\n",
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
    "cc = cc.apply(lambda r: tuple(r), axis=1).apply(np.array).to_list()\n",
    "cc = np.reshape(cc, (3802, 156))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_mf = PCA(n_components=38, random_state=0)\n",
    "mf_t = transformer_mf.fit_transform(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079184773504919"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transformer_mf.explained_variance_ratio_)"
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rootlocus/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3217: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mf_inputs (InputLayer)          (None, 142)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bp_inputs (InputLayer)          (None, 1039)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cc_inputs (InputLayer)          (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mf_enc (Dense)                  (None, 256)          36608       mf_inputs[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bp_enc (Dense)                  (None, 1024)         1064960     bp_inputs[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cc_enc (Dense)                  (None, 256)          40192       cc_inputs[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1536)         0           mf_enc[0][0]                     \n",
      "                                                                 bp_enc[0][0]                     \n",
      "                                                                 cc_enc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "go_enc (Dense)                  (None, 256)          393472      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,535,232\n",
      "Trainable params: 1,535,232\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MF Part\n",
    "mf_inputs = Input(name='mf_inputs', shape=(142,))\n",
    "mf_enc = Dense(256, activation='selu', kernel_initializer='lecun_normal', name='mf_enc', \n",
    "            kernel_constraint=UnitNorm(axis=0))(mf_inputs)\n",
    "\n",
    "# BP Part\n",
    "bp_inputs = Input(name='bp_inputs', shape=(1039, ))\n",
    "bp_enc = Dense(1024, activation='selu', kernel_initializer='lecun_normal', name='bp_enc', \n",
    "            kernel_constraint=UnitNorm(axis=0))(bp_inputs)\n",
    "\n",
    "# CC Part\n",
    "cc_inputs = Input(name='cc_inputs', shape=(156, ))\n",
    "cc_enc = Dense(256, activation='selu', kernel_initializer='lecun_normal', name='cc_enc', \n",
    "            kernel_constraint=UnitNorm(axis=0))(cc_inputs)\n",
    "\n",
    "# Encoder\n",
    "concat = concatenate([mf_enc, bp_enc, cc_enc], axis=-1)\n",
    "enc = Dense(256, activation='selu', kernel_initializer='lecun_normal', name='go_enc', \n",
    "            kernel_constraint=UnitNorm(axis=0))(concat)\n",
    "\n",
    "encoder = Model([mf_inputs, bp_inputs, cc_inputs], enc)\n",
    "encoder.summary()"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_bp = PCA(n_components=256, random_state=0)\n",
    "bp_t = transformer_bp.fit_transform(bp)"
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mf_inputs (InputLayer)          (None, 142)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bp_inputs (InputLayer)          (None, 1039)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cc_inputs (InputLayer)          (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mf_enc (Dense)                  (None, 256)          36608       mf_inputs[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bp_enc (Dense)                  (None, 1024)         1064960     bp_inputs[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cc_enc (Dense)                  (None, 256)          40192       cc_inputs[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1536)         0           mf_enc[0][0]                     \n",
      "                                                                 bp_enc[0][0]                     \n",
      "                                                                 cc_enc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "go_enc (Dense)                  (None, 256)          393472      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "go_dec (Dense)                  (None, 1024)         263168      go_enc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mf_out (Dense)                  (None, 142)          145550      go_dec[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bp_out (Dense)                  (None, 1039)         1064975     go_dec[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cc_out (Dense)                  (None, 156)          159900      go_dec[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,168,825\n",
      "Trainable params: 3,168,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoder\n",
    "dec_1 = Dense(1024, activation='selu', kernel_initializer='lecun_normal', name='go_dec', \n",
    "            kernel_constraint=UnitNorm(axis=0))(enc)\n",
    "mf_out = Dense(142, activation='sigmoid', name='mf_out')(dec_1)\n",
    "bp_out = Dense(1039, activation='sigmoid', name='bp_out')(dec_1)\n",
    "cc_out = Dense(156, activation='sigmoid', name='cc_out')(dec_1)\n",
    "\n",
    "autoencoder = Model([mf_inputs, bp_inputs, cc_inputs], [mf_out, bp_out, cc_out])\n",
    "autoencoder.summary()\n",
    "\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, \n",
    "                    decay=0, amsgrad=False)\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333718767057071"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transformer_bp.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_cc = PCA(n_components=64, random_state=0)\n",
    "cc_t = transformer_cc.fit_transform(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9569880055068711"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transformer_cc.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3802, 1337)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with all together\n",
    "all_go = np.hstack((mf, bp, cc))\n",
    "all_go.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_all = PCA(n_components=312, random_state=0)\n",
    "go_t = transformer_all.fit_transform(all_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9273008325272347"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transformer_all.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(all_go)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, RobustScaler, MaxAbsScaler, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.hstack((sequences, mf, bp, cc))\n",
    "scaler = MaxAbsScaler()\n",
    "total_s = scaler.fit_transform(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00166203,  0.00533365, -0.00076066, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00023285,  0.00454736, -0.01030456, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.00173896,  0.0047178 , -0.0032096 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.00824014,  0.00314153, -0.012838  , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00072223,  0.0008972 , -0.01124037, ...,  0.05650187,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.00281946,  0.00623423, -0.0073554 , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3802, 2361)"
=======
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3231 samples, validate on 571 samples\n",
      "Epoch 1/600\n",
      "3231/3231 [==============================] - 1s 354us/step - loss: 0.8636 - mf_out_loss: 0.2497 - bp_out_loss: 0.3157 - cc_out_loss: 0.2982 - mf_out_acc: 0.9047 - bp_out_acc: 0.8735 - cc_out_acc: 0.8809 - val_loss: 0.4638 - val_mf_out_loss: 0.1248 - val_bp_out_loss: 0.1730 - val_cc_out_loss: 0.1660 - val_mf_out_acc: 0.9573 - val_bp_out_acc: 0.9408 - val_cc_out_acc: 0.9411\n",
      "Epoch 2/600\n",
      "3231/3231 [==============================] - 0s 78us/step - loss: 0.4476 - mf_out_loss: 0.1065 - bp_out_loss: 0.1968 - cc_out_loss: 0.1443 - mf_out_acc: 0.9632 - bp_out_acc: 0.9264 - cc_out_acc: 0.9463 - val_loss: 0.3110 - val_mf_out_loss: 0.0745 - val_bp_out_loss: 0.1340 - val_cc_out_loss: 0.1025 - val_mf_out_acc: 0.9758 - val_bp_out_acc: 0.9524 - val_cc_out_acc: 0.9625\n",
      "Epoch 3/600\n",
      "3231/3231 [==============================] - 0s 78us/step - loss: 0.3172 - mf_out_loss: 0.0681 - bp_out_loss: 0.1544 - cc_out_loss: 0.0946 - mf_out_acc: 0.9775 - bp_out_acc: 0.9420 - cc_out_acc: 0.9659 - val_loss: 0.2358 - val_mf_out_loss: 0.0544 - val_bp_out_loss: 0.1062 - val_cc_out_loss: 0.0752 - val_mf_out_acc: 0.9819 - val_bp_out_acc: 0.9621 - val_cc_out_acc: 0.9732\n",
      "Epoch 4/600\n",
      "3231/3231 [==============================] - 0s 78us/step - loss: 0.2409 - mf_out_loss: 0.0486 - bp_out_loss: 0.1243 - cc_out_loss: 0.0680 - mf_out_acc: 0.9842 - bp_out_acc: 0.9536 - cc_out_acc: 0.9766 - val_loss: 0.1907 - val_mf_out_loss: 0.0439 - val_bp_out_loss: 0.0886 - val_cc_out_loss: 0.0583 - val_mf_out_acc: 0.9848 - val_bp_out_acc: 0.9687 - val_cc_out_acc: 0.9799\n",
      "Epoch 5/600\n",
      "3231/3231 [==============================] - 0s 76us/step - loss: 0.1910 - mf_out_loss: 0.0364 - bp_out_loss: 0.1040 - cc_out_loss: 0.0506 - mf_out_acc: 0.9887 - bp_out_acc: 0.9613 - cc_out_acc: 0.9837 - val_loss: 0.1603 - val_mf_out_loss: 0.0358 - val_bp_out_loss: 0.0766 - val_cc_out_loss: 0.0479 - val_mf_out_acc: 0.9879 - val_bp_out_acc: 0.9727 - val_cc_out_acc: 0.9833\n",
      "Epoch 6/600\n",
      "3231/3231 [==============================] - 0s 76us/step - loss: 0.1576 - mf_out_loss: 0.0284 - bp_out_loss: 0.0896 - cc_out_loss: 0.0396 - mf_out_acc: 0.9915 - bp_out_acc: 0.9670 - cc_out_acc: 0.9878 - val_loss: 0.1400 - val_mf_out_loss: 0.0303 - val_bp_out_loss: 0.0693 - val_cc_out_loss: 0.0404 - val_mf_out_acc: 0.9899 - val_bp_out_acc: 0.9754 - val_cc_out_acc: 0.9864\n",
      "Epoch 7/600\n",
      "3231/3231 [==============================] - 0s 81us/step - loss: 0.1321 - mf_out_loss: 0.0226 - bp_out_loss: 0.0783 - cc_out_loss: 0.0313 - mf_out_acc: 0.9937 - bp_out_acc: 0.9714 - cc_out_acc: 0.9910 - val_loss: 0.1243 - val_mf_out_loss: 0.0268 - val_bp_out_loss: 0.0619 - val_cc_out_loss: 0.0356 - val_mf_out_acc: 0.9908 - val_bp_out_acc: 0.9780 - val_cc_out_acc: 0.9879\n",
      "Epoch 8/600\n",
      "3231/3231 [==============================] - 0s 82us/step - loss: 0.1125 - mf_out_loss: 0.0179 - bp_out_loss: 0.0691 - cc_out_loss: 0.0255 - mf_out_acc: 0.9954 - bp_out_acc: 0.9751 - cc_out_acc: 0.9931 - val_loss: 0.1121 - val_mf_out_loss: 0.0234 - val_bp_out_loss: 0.0573 - val_cc_out_loss: 0.0315 - val_mf_out_acc: 0.9923 - val_bp_out_acc: 0.9794 - val_cc_out_acc: 0.9895\n",
      "Epoch 9/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0972 - mf_out_loss: 0.0144 - bp_out_loss: 0.0617 - cc_out_loss: 0.0211 - mf_out_acc: 0.9967 - bp_out_acc: 0.9779 - cc_out_acc: 0.9946 - val_loss: 0.1035 - val_mf_out_loss: 0.0215 - val_bp_out_loss: 0.0532 - val_cc_out_loss: 0.0288 - val_mf_out_acc: 0.9928 - val_bp_out_acc: 0.9806 - val_cc_out_acc: 0.9901\n",
      "Epoch 10/600\n",
      "3231/3231 [==============================] - 0s 79us/step - loss: 0.0859 - mf_out_loss: 0.0121 - bp_out_loss: 0.0560 - cc_out_loss: 0.0177 - mf_out_acc: 0.9975 - bp_out_acc: 0.9801 - cc_out_acc: 0.9957 - val_loss: 0.0956 - val_mf_out_loss: 0.0195 - val_bp_out_loss: 0.0495 - val_cc_out_loss: 0.0266 - val_mf_out_acc: 0.9933 - val_bp_out_acc: 0.9823 - val_cc_out_acc: 0.9910\n",
      "Epoch 11/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0756 - mf_out_loss: 0.0101 - bp_out_loss: 0.0504 - cc_out_loss: 0.0151 - mf_out_acc: 0.9982 - bp_out_acc: 0.9823 - cc_out_acc: 0.9968 - val_loss: 0.0897 - val_mf_out_loss: 0.0181 - val_bp_out_loss: 0.0468 - val_cc_out_loss: 0.0249 - val_mf_out_acc: 0.9939 - val_bp_out_acc: 0.9829 - val_cc_out_acc: 0.9917\n",
      "Epoch 12/600\n",
      "3231/3231 [==============================] - 0s 78us/step - loss: 0.0668 - mf_out_loss: 0.0086 - bp_out_loss: 0.0455 - cc_out_loss: 0.0127 - mf_out_acc: 0.9987 - bp_out_acc: 0.9842 - cc_out_acc: 0.9976 - val_loss: 0.0854 - val_mf_out_loss: 0.0175 - val_bp_out_loss: 0.0441 - val_cc_out_loss: 0.0239 - val_mf_out_acc: 0.9939 - val_bp_out_acc: 0.9842 - val_cc_out_acc: 0.9918\n",
      "Epoch 13/600\n",
      "3231/3231 [==============================] - 0s 82us/step - loss: 0.0600 - mf_out_loss: 0.0074 - bp_out_loss: 0.0415 - cc_out_loss: 0.0110 - mf_out_acc: 0.9990 - bp_out_acc: 0.9858 - cc_out_acc: 0.9981 - val_loss: 0.0811 - val_mf_out_loss: 0.0166 - val_bp_out_loss: 0.0420 - val_cc_out_loss: 0.0225 - val_mf_out_acc: 0.9945 - val_bp_out_acc: 0.9847 - val_cc_out_acc: 0.9921\n",
      "Epoch 14/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0544 - mf_out_loss: 0.0064 - bp_out_loss: 0.0383 - cc_out_loss: 0.0097 - mf_out_acc: 0.9992 - bp_out_acc: 0.9870 - cc_out_acc: 0.9985 - val_loss: 0.0790 - val_mf_out_loss: 0.0165 - val_bp_out_loss: 0.0405 - val_cc_out_loss: 0.0220 - val_mf_out_acc: 0.9945 - val_bp_out_acc: 0.9854 - val_cc_out_acc: 0.9925\n",
      "Epoch 15/600\n",
      "3231/3231 [==============================] - 0s 79us/step - loss: 0.0496 - mf_out_loss: 0.0057 - bp_out_loss: 0.0353 - cc_out_loss: 0.0086 - mf_out_acc: 0.9994 - bp_out_acc: 0.9882 - cc_out_acc: 0.9988 - val_loss: 0.0754 - val_mf_out_loss: 0.0156 - val_bp_out_loss: 0.0386 - val_cc_out_loss: 0.0211 - val_mf_out_acc: 0.9947 - val_bp_out_acc: 0.9860 - val_cc_out_acc: 0.9929\n",
      "Epoch 16/600\n",
      "3231/3231 [==============================] - 0s 76us/step - loss: 0.0448 - mf_out_loss: 0.0050 - bp_out_loss: 0.0323 - cc_out_loss: 0.0075 - mf_out_acc: 0.9996 - bp_out_acc: 0.9894 - cc_out_acc: 0.9991 - val_loss: 0.0733 - val_mf_out_loss: 0.0155 - val_bp_out_loss: 0.0373 - val_cc_out_loss: 0.0205 - val_mf_out_acc: 0.9947 - val_bp_out_acc: 0.9863 - val_cc_out_acc: 0.9931\n",
      "Epoch 17/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0410 - mf_out_loss: 0.0045 - bp_out_loss: 0.0298 - cc_out_loss: 0.0067 - mf_out_acc: 0.9997 - bp_out_acc: 0.9904 - cc_out_acc: 0.9994 - val_loss: 0.0715 - val_mf_out_loss: 0.0153 - val_bp_out_loss: 0.0363 - val_cc_out_loss: 0.0199 - val_mf_out_acc: 0.9948 - val_bp_out_acc: 0.9869 - val_cc_out_acc: 0.9932\n",
      "Epoch 18/600\n",
      "3231/3231 [==============================] - 0s 79us/step - loss: 0.0376 - mf_out_loss: 0.0040 - bp_out_loss: 0.0276 - cc_out_loss: 0.0059 - mf_out_acc: 0.9998 - bp_out_acc: 0.9912 - cc_out_acc: 0.9994 - val_loss: 0.0692 - val_mf_out_loss: 0.0149 - val_bp_out_loss: 0.0350 - val_cc_out_loss: 0.0194 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9874 - val_cc_out_acc: 0.9935\n",
      "Epoch 19/600\n",
      "3231/3231 [==============================] - 0s 83us/step - loss: 0.0344 - mf_out_loss: 0.0036 - bp_out_loss: 0.0255 - cc_out_loss: 0.0053 - mf_out_acc: 0.9998 - bp_out_acc: 0.9921 - cc_out_acc: 0.9996 - val_loss: 0.0677 - val_mf_out_loss: 0.0148 - val_bp_out_loss: 0.0339 - val_cc_out_loss: 0.0191 - val_mf_out_acc: 0.9949 - val_bp_out_acc: 0.9878 - val_cc_out_acc: 0.9936\n",
      "Epoch 20/600\n",
      "3231/3231 [==============================] - 0s 75us/step - loss: 0.0322 - mf_out_loss: 0.0033 - bp_out_loss: 0.0239 - cc_out_loss: 0.0050 - mf_out_acc: 0.9999 - bp_out_acc: 0.9927 - cc_out_acc: 0.9996 - val_loss: 0.0684 - val_mf_out_loss: 0.0152 - val_bp_out_loss: 0.0338 - val_cc_out_loss: 0.0194 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9879 - val_cc_out_acc: 0.9935\n",
      "Epoch 21/600\n",
      "3231/3231 [==============================] - 0s 83us/step - loss: 0.0300 - mf_out_loss: 0.0031 - bp_out_loss: 0.0225 - cc_out_loss: 0.0045 - mf_out_acc: 0.9999 - bp_out_acc: 0.9932 - cc_out_acc: 0.9997 - val_loss: 0.0644 - val_mf_out_loss: 0.0141 - val_bp_out_loss: 0.0322 - val_cc_out_loss: 0.0181 - val_mf_out_acc: 0.9953 - val_bp_out_acc: 0.9884 - val_cc_out_acc: 0.9940\n",
      "Epoch 22/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3231/3231 [==============================] - 0s 76us/step - loss: 0.0279 - mf_out_loss: 0.0028 - bp_out_loss: 0.0209 - cc_out_loss: 0.0041 - mf_out_acc: 0.9999 - bp_out_acc: 0.9938 - cc_out_acc: 0.9998 - val_loss: 0.0647 - val_mf_out_loss: 0.0145 - val_bp_out_loss: 0.0317 - val_cc_out_loss: 0.0185 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9886 - val_cc_out_acc: 0.9937\n",
      "Epoch 23/600\n",
      "3231/3231 [==============================] - 0s 75us/step - loss: 0.0259 - mf_out_loss: 0.0026 - bp_out_loss: 0.0196 - cc_out_loss: 0.0038 - mf_out_acc: 0.9999 - bp_out_acc: 0.9943 - cc_out_acc: 0.9998 - val_loss: 0.0638 - val_mf_out_loss: 0.0144 - val_bp_out_loss: 0.0313 - val_cc_out_loss: 0.0180 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9888 - val_cc_out_acc: 0.9941\n",
      "Epoch 24/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0241 - mf_out_loss: 0.0024 - bp_out_loss: 0.0183 - cc_out_loss: 0.0035 - mf_out_acc: 1.0000 - bp_out_acc: 0.9948 - cc_out_acc: 0.9999 - val_loss: 0.0639 - val_mf_out_loss: 0.0145 - val_bp_out_loss: 0.0306 - val_cc_out_loss: 0.0188 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9891 - val_cc_out_acc: 0.9937\n",
      "Epoch 25/600\n",
      "3231/3231 [==============================] - 0s 82us/step - loss: 0.0224 - mf_out_loss: 0.0022 - bp_out_loss: 0.0170 - cc_out_loss: 0.0032 - mf_out_acc: 1.0000 - bp_out_acc: 0.9953 - cc_out_acc: 0.9999 - val_loss: 0.0617 - val_mf_out_loss: 0.0142 - val_bp_out_loss: 0.0297 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9953 - val_bp_out_acc: 0.9893 - val_cc_out_acc: 0.9941\n",
      "Epoch 26/600\n",
      "3231/3231 [==============================] - 0s 79us/step - loss: 0.0212 - mf_out_loss: 0.0021 - bp_out_loss: 0.0161 - cc_out_loss: 0.0030 - mf_out_acc: 1.0000 - bp_out_acc: 0.9957 - cc_out_acc: 0.9999 - val_loss: 0.0626 - val_mf_out_loss: 0.0147 - val_bp_out_loss: 0.0300 - val_cc_out_loss: 0.0179 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9893 - val_cc_out_acc: 0.9941\n",
      "Epoch 27/600\n",
      "3231/3231 [==============================] - 0s 82us/step - loss: 0.0197 - mf_out_loss: 0.0019 - bp_out_loss: 0.0150 - cc_out_loss: 0.0028 - mf_out_acc: 1.0000 - bp_out_acc: 0.9961 - cc_out_acc: 0.9999 - val_loss: 0.0615 - val_mf_out_loss: 0.0146 - val_bp_out_loss: 0.0295 - val_cc_out_loss: 0.0174 - val_mf_out_acc: 0.9953 - val_bp_out_acc: 0.9895 - val_cc_out_acc: 0.9943\n",
      "Epoch 28/600\n",
      "3231/3231 [==============================] - 0s 79us/step - loss: 0.0186 - mf_out_loss: 0.0018 - bp_out_loss: 0.0142 - cc_out_loss: 0.0026 - mf_out_acc: 1.0000 - bp_out_acc: 0.9963 - cc_out_acc: 1.0000 - val_loss: 0.0613 - val_mf_out_loss: 0.0142 - val_bp_out_loss: 0.0291 - val_cc_out_loss: 0.0180 - val_mf_out_acc: 0.9953 - val_bp_out_acc: 0.9896 - val_cc_out_acc: 0.9941\n",
      "Epoch 29/600\n",
      "3231/3231 [==============================] - 0s 81us/step - loss: 0.0178 - mf_out_loss: 0.0017 - bp_out_loss: 0.0137 - cc_out_loss: 0.0024 - mf_out_acc: 1.0000 - bp_out_acc: 0.9965 - cc_out_acc: 1.0000 - val_loss: 0.0617 - val_mf_out_loss: 0.0147 - val_bp_out_loss: 0.0290 - val_cc_out_loss: 0.0179 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9898 - val_cc_out_acc: 0.9942\n",
      "Epoch 30/600\n",
      "3231/3231 [==============================] - 0s 74us/step - loss: 0.0169 - mf_out_loss: 0.0016 - bp_out_loss: 0.0129 - cc_out_loss: 0.0023 - mf_out_acc: 1.0000 - bp_out_acc: 0.9968 - cc_out_acc: 1.0000 - val_loss: 0.0649 - val_mf_out_loss: 0.0159 - val_bp_out_loss: 0.0299 - val_cc_out_loss: 0.0191 - val_mf_out_acc: 0.9949 - val_bp_out_acc: 0.9896 - val_cc_out_acc: 0.9938\n",
      "Epoch 31/600\n",
      "3231/3231 [==============================] - 0s 76us/step - loss: 0.0171 - mf_out_loss: 0.0017 - bp_out_loss: 0.0129 - cc_out_loss: 0.0024 - mf_out_acc: 1.0000 - bp_out_acc: 0.9967 - cc_out_acc: 0.9999 - val_loss: 0.0617 - val_mf_out_loss: 0.0151 - val_bp_out_loss: 0.0289 - val_cc_out_loss: 0.0177 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9899 - val_cc_out_acc: 0.9944\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 32/600\n",
      "3231/3231 [==============================] - 0s 74us/step - loss: 0.0146 - mf_out_loss: 0.0014 - bp_out_loss: 0.0111 - cc_out_loss: 0.0021 - mf_out_acc: 1.0000 - bp_out_acc: 0.9976 - cc_out_acc: 1.0000 - val_loss: 0.0601 - val_mf_out_loss: 0.0148 - val_bp_out_loss: 0.0279 - val_cc_out_loss: 0.0175 - val_mf_out_acc: 0.9954 - val_bp_out_acc: 0.9903 - val_cc_out_acc: 0.9943\n",
      "Epoch 33/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0131 - mf_out_loss: 0.0013 - bp_out_loss: 0.0100 - cc_out_loss: 0.0018 - mf_out_acc: 1.0000 - bp_out_acc: 0.9981 - cc_out_acc: 1.0000 - val_loss: 0.0601 - val_mf_out_loss: 0.0149 - val_bp_out_loss: 0.0275 - val_cc_out_loss: 0.0177 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9904 - val_cc_out_acc: 0.9942\n",
      "Epoch 34/600\n",
      "3231/3231 [==============================] - 0s 81us/step - loss: 0.0124 - mf_out_loss: 0.0012 - bp_out_loss: 0.0095 - cc_out_loss: 0.0017 - mf_out_acc: 1.0000 - bp_out_acc: 0.9983 - cc_out_acc: 1.0000 - val_loss: 0.0598 - val_mf_out_loss: 0.0148 - val_bp_out_loss: 0.0274 - val_cc_out_loss: 0.0175 - val_mf_out_acc: 0.9954 - val_bp_out_acc: 0.9904 - val_cc_out_acc: 0.9944\n",
      "Epoch 35/600\n",
      "3231/3231 [==============================] - 0s 75us/step - loss: 0.0119 - mf_out_loss: 0.0012 - bp_out_loss: 0.0091 - cc_out_loss: 0.0016 - mf_out_acc: 1.0000 - bp_out_acc: 0.9984 - cc_out_acc: 1.0000 - val_loss: 0.0602 - val_mf_out_loss: 0.0151 - val_bp_out_loss: 0.0274 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9904 - val_cc_out_acc: 0.9943\n",
      "Epoch 36/600\n",
      "3231/3231 [==============================] - 0s 74us/step - loss: 0.0117 - mf_out_loss: 0.0011 - bp_out_loss: 0.0089 - cc_out_loss: 0.0016 - mf_out_acc: 1.0000 - bp_out_acc: 0.9985 - cc_out_acc: 1.0000 - val_loss: 0.0601 - val_mf_out_loss: 0.0149 - val_bp_out_loss: 0.0273 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9953 - val_bp_out_acc: 0.9905 - val_cc_out_acc: 0.9943\n",
      "Epoch 37/600\n",
      "3231/3231 [==============================] - 0s 74us/step - loss: 0.0113 - mf_out_loss: 0.0011 - bp_out_loss: 0.0086 - cc_out_loss: 0.0016 - mf_out_acc: 1.0000 - bp_out_acc: 0.9986 - cc_out_acc: 1.0000 - val_loss: 0.0602 - val_mf_out_loss: 0.0152 - val_bp_out_loss: 0.0273 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9906 - val_cc_out_acc: 0.9943\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 38/600\n",
      "3231/3231 [==============================] - 0s 73us/step - loss: 0.0107 - mf_out_loss: 0.0011 - bp_out_loss: 0.0081 - cc_out_loss: 0.0015 - mf_out_acc: 1.0000 - bp_out_acc: 0.9988 - cc_out_acc: 1.0000 - val_loss: 0.0596 - val_mf_out_loss: 0.0150 - val_bp_out_loss: 0.0270 - val_cc_out_loss: 0.0176 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9906 - val_cc_out_acc: 0.9943\n",
      "Epoch 39/600\n",
      "3231/3231 [==============================] - 0s 75us/step - loss: 0.0104 - mf_out_loss: 0.0010 - bp_out_loss: 0.0079 - cc_out_loss: 0.0014 - mf_out_acc: 1.0000 - bp_out_acc: 0.9989 - cc_out_acc: 1.0000 - val_loss: 0.0596 - val_mf_out_loss: 0.0150 - val_bp_out_loss: 0.0269 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9906 - val_cc_out_acc: 0.9943\n",
      "Epoch 40/600\n",
      "3231/3231 [==============================] - 0s 77us/step - loss: 0.0102 - mf_out_loss: 0.0010 - bp_out_loss: 0.0078 - cc_out_loss: 0.0014 - mf_out_acc: 1.0000 - bp_out_acc: 0.9989 - cc_out_acc: 1.0000 - val_loss: 0.0601 - val_mf_out_loss: 0.0152 - val_bp_out_loss: 0.0270 - val_cc_out_loss: 0.0179 - val_mf_out_acc: 0.9951 - val_bp_out_acc: 0.9907 - val_cc_out_acc: 0.9944\n",
      "Epoch 41/600\n",
      "3231/3231 [==============================] - 0s 80us/step - loss: 0.0101 - mf_out_loss: 0.0010 - bp_out_loss: 0.0076 - cc_out_loss: 0.0014 - mf_out_acc: 1.0000 - bp_out_acc: 0.9990 - cc_out_acc: 1.0000 - val_loss: 0.0597 - val_mf_out_loss: 0.0151 - val_bp_out_loss: 0.0269 - val_cc_out_loss: 0.0177 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9907 - val_cc_out_acc: 0.9944\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 42/600\n",
      "3231/3231 [==============================] - 0s 80us/step - loss: 0.0098 - mf_out_loss: 9.8396e-04 - bp_out_loss: 0.0074 - cc_out_loss: 0.0014 - mf_out_acc: 1.0000 - bp_out_acc: 0.9991 - cc_out_acc: 1.0000 - val_loss: 0.0597 - val_mf_out_loss: 0.0151 - val_bp_out_loss: 0.0268 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9953 - val_bp_out_acc: 0.9908 - val_cc_out_acc: 0.9943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/600\n",
      "3231/3231 [==============================] - 0s 80us/step - loss: 0.0097 - mf_out_loss: 9.7484e-04 - bp_out_loss: 0.0073 - cc_out_loss: 0.0014 - mf_out_acc: 1.0000 - bp_out_acc: 0.9991 - cc_out_acc: 1.0000 - val_loss: 0.0598 - val_mf_out_loss: 0.0151 - val_bp_out_loss: 0.0268 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9907 - val_cc_out_acc: 0.9943\n",
      "Epoch 44/600\n",
      "3231/3231 [==============================] - 0s 79us/step - loss: 0.0096 - mf_out_loss: 9.6883e-04 - bp_out_loss: 0.0073 - cc_out_loss: 0.0013 - mf_out_acc: 1.0000 - bp_out_acc: 0.9991 - cc_out_acc: 1.0000 - val_loss: 0.0596 - val_mf_out_loss: 0.0151 - val_bp_out_loss: 0.0268 - val_cc_out_loss: 0.0178 - val_mf_out_acc: 0.9952 - val_bp_out_acc: 0.9908 - val_cc_out_acc: 0.9943\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f722c196690>"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "total_s.shape"
=======
    "autoencoder.fit([mf, bp, cc], [mf, bp, cc], epochs=600, batch_size=128, shuffle=True, validation_split=0.15, callbacks=[es, rlr])"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_all = PCA(n_components=256, random_state=0)\n",
    "total_s_pca = transformer_all.fit_transform(total_s)"
=======
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embs = encoder.predict([mf, bp, cc])"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794200295187514"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(transformer_all.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
=======
   "execution_count": 23,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([[ 2.43464681e-01, -1.71328293e-01, -1.80199571e-01, ...,\n",
       "         3.37440466e-02, -3.54122919e-02, -5.77426220e-03],\n",
       "       [ 3.32335973e-01, -1.37934878e-03, -2.33275436e-01, ...,\n",
       "         6.81130159e-03,  1.50990633e-02, -1.64262196e-02],\n",
       "       [ 1.20980173e-01, -1.50224016e-01, -7.58417595e-02, ...,\n",
       "         9.94416835e-03, -7.51726861e-05,  7.38656928e-03],\n",
       "       ...,\n",
       "       [ 3.21230582e-01, -1.33781331e-01, -2.77296301e-01, ...,\n",
       "         1.46865442e-02,  1.31261873e-02,  2.84415919e-02],\n",
       "       [ 2.16190868e-01, -1.99316691e-01, -3.07875109e-01, ...,\n",
       "         1.08904488e-03,  1.34293719e-02,  5.92293495e-03],\n",
       "       [ 2.88649822e-01, -1.56141697e-01, -2.85664720e-01, ...,\n",
       "         1.48168371e-02, -2.24073838e-02,  1.29059504e-02]])"
      ]
     },
     "execution_count": 40,
=======
       "(3802, 256)"
      ]
     },
     "execution_count": 23,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "total_s_pca"
=======
    "final_embs.shape"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df.gene.to_numpy()\n",
    "prot_dict = defaultdict()"
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_embs = pd.DataFrame(final_embs)\n",
    "go_embs = go_embs.apply(lambda r: tuple(r), axis=1).apply(np.array) \n",
    "df['go_embs'] = go_embs\n",
    "seq_embs = df['seq_embs'].to_list()\n",
    "go_embs = df['go_embs'].to_list()"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,val in zip(names, total_s):\n",
    "    prot_dict[n] = val.tolist()"
=======
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = np.concatenate([seq_embs, go_embs], axis=-1)\n",
    "all_embs = pd.DataFrame(all_embs)\n",
    "all_embs = all_embs.apply(lambda r: tuple(r), axis=1).apply(np.array)\n",
    "df['embs'] = all_embs"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = json.dumps(prot_dict)\n",
    "f = open('seq_go_embs_qt.json', 'w')\n",
    "f.write(js)\n",
    "f.close()"
=======
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['seq_embs', 'go_embs'], axis=1)"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Perturbation' in prot_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CorEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rootlocus/Desktop/NTUA/Systems_Biology_Lab/DiplomaThesis/LinearCorex\n"
     ]
    }
   ],
   "source": [
    "cd /home/rootlocus/Desktop/NTUA/Systems_Biology_Lab/DiplomaThesis/LinearCorex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corex as ce\n",
    "import linearcorex as lc\n",
    "import scipy.sparse as ss"
=======
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_tot = np.concatenate([list(df['seq_embs']),list(df['go_embs'])], axis=1)\n",
    "norm = Normalizer()\n",
    "embs_tot_norm = norm.fit_transform(embs_tot)\n",
    "genes = df['gene'].to_numpy()"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "tots = np.hstack((mf, bp, cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CorEx with 128 latent factors\n"
     ]
    }
   ],
   "source": [
    "output = lc.Corex(n_hidden=128, verbose=True, gaussianize='outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: step size becoming too small\n",
      "2584 iterations to tol: 0.000010, TC=254.045609\n",
      "566 iterations to tol: 0.000010, TC=450.474930\n",
      "734 iterations to tol: 0.000010, TC=562.745605\n",
      "Warning: step size becoming too small\n",
      "308 iterations to tol: 0.000010, TC=622.067825\n",
      "107 iterations to tol: 0.000010, TC=654.406006\n",
      "Warning: step size becoming too small\n",
      "45 iterations to tol: 0.000010, TC=673.549866\n",
      "Warning: step size becoming too small\n",
      "8 iterations to tol: 0.000010, TC=708.800217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<linearcorex.linearcorex.Corex at 0x7f8c155b3490>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.fit(tots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.958, -0.16 ,  3.132, ...,  4.448,  0.696, -0.84 ],\n",
       "       [ 1.959, -0.742, -0.32 , ..., -0.322,  1.162,  2.373],\n",
       "       [ 1.959, -0.849,  3.119, ..., -1.   , -0.817,  0.915],\n",
       "       ...,\n",
       "       [ 1.959, -0.53 ,  3.134, ...,  0.349, -0.553, -0.434],\n",
       "       [ 1.959, -1.051,  3.13 , ..., -0.399,  0.042, -0.622],\n",
       "       [ 1.958, -0.148, -0.332, ..., -0.269,  0.049,  2.927]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tots_lc = output.transform(tots)\n",
    "tots_lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.999, -0.067,  0.997, ...,  0.841,  0.123, -0.22 ],\n",
       "       [ 0.999, -0.311, -0.102, ..., -0.061,  0.205,  0.621],\n",
       "       [ 0.999, -0.356,  0.993, ..., -0.189, -0.144,  0.239],\n",
       "       ...,\n",
       "       [ 0.999, -0.222,  0.998, ...,  0.066, -0.098, -0.113],\n",
       "       [ 0.999, -0.44 ,  0.996, ..., -0.075,  0.007, -0.163],\n",
       "       [ 0.999, -0.062, -0.106, ..., -0.051,  0.009,  0.766]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "tots_lc_sc = scaler.fit_transform(tots_lc)\n",
    "tots_lc_sc"
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_prot = defaultdict(list)\n",
    "for gene, emb in zip(genes, embs_tot_norm):\n",
    "    dict_prot[gene] = emb"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 116,
=======
   "execution_count": 31,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([  4,  24,  24, ...,  21, 126, 126])"
      ]
     },
     "execution_count": 116,
=======
       "array([ 6.80741737e-04, -5.20140186e-03, -4.91125616e-03, -7.13793314e-03,\n",
       "        2.60472890e-03, -4.94904897e-03, -4.01444793e-03,  4.03560309e-03,\n",
       "        9.37388638e-04,  1.40363649e-03, -6.13986984e-03,  4.78779666e-03,\n",
       "        1.61745967e-03,  6.40811102e-04, -6.73815890e-03, -4.66001559e-03,\n",
       "        2.49348127e-04,  2.50794964e-03,  5.72694868e-04, -2.91368613e-03,\n",
       "        3.84578379e-03, -3.28111180e-03,  4.07867394e-03,  1.41839305e-03,\n",
       "        1.77334747e-02,  4.73109338e-06,  5.49182629e-03, -3.53519591e-03,\n",
       "        6.83443761e-03,  2.01057383e-04,  1.47041768e-02, -4.43995079e-03,\n",
       "        3.31080599e-03,  3.38244188e-03,  4.29012825e-03, -2.62126097e-03,\n",
       "        3.78287608e-03,  7.25703195e-03,  1.10038558e-03,  6.64741820e-04,\n",
       "        1.57246262e-03, -8.52159761e-03, -2.43478010e-03, -2.19094682e-03,\n",
       "       -3.18241669e-03, -6.97733174e-03,  2.68247417e-03,  1.76729385e-03,\n",
       "       -3.00141515e-03,  5.51224713e-03, -4.79580830e-03,  3.80675417e-03,\n",
       "        9.35875232e-03,  5.86788516e-04,  7.05225772e-03, -2.72020328e-03,\n",
       "       -4.78526483e-03,  5.04949210e-03, -4.10635883e-04, -2.21582358e-03,\n",
       "       -3.39165574e-03, -6.60854266e-04,  1.72978381e-03,  1.55540495e-03,\n",
       "       -4.86803568e-04,  1.89179162e-03,  1.43267363e-03,  2.42218174e-03,\n",
       "       -8.57320489e-03, -2.29762576e-03, -6.50176486e-04,  3.45806145e-03,\n",
       "        3.40013235e-03, -5.72261014e-03,  3.28323815e-03,  1.22445941e-02,\n",
       "        4.21351374e-03, -6.54625012e-03,  8.98190229e-03, -3.68432939e-03,\n",
       "        1.45863669e-03, -4.04920642e-03,  7.77035824e-03,  4.22817280e-03,\n",
       "        1.98437315e-03,  1.16173903e-03, -7.73558100e-04, -6.23177218e-04,\n",
       "        2.23179804e-03,  2.25242113e-03, -2.22296202e-03, -7.47587965e-03,\n",
       "        3.35161177e-03,  6.51382912e-03,  2.11276164e-03, -8.67988124e-03,\n",
       "       -2.35953465e-03,  2.22674440e-03,  1.96174351e-03,  6.48372266e-03,\n",
       "       -1.07667417e-03, -1.94053063e-03,  1.87502496e-03, -8.99443662e-03,\n",
       "        6.04439498e-03, -2.58892991e-04,  1.75251870e-03,  7.03968329e-03,\n",
       "       -4.33610828e-03, -1.13105507e-03,  1.57110262e-03,  1.23878588e-02,\n",
       "       -9.26687537e-04,  1.16004204e-02,  1.07479648e-03, -3.69163257e-03,\n",
       "       -3.52573987e-03, -1.91724896e-03, -1.50739008e-03, -7.72031468e-03,\n",
       "       -1.40392379e-03, -4.92659596e-04,  5.22047756e-03, -2.21994144e-03,\n",
       "       -4.01211496e-03, -5.99043112e-03, -2.81257366e-03, -2.70758908e-03,\n",
       "       -3.81137672e-02,  1.08683525e-02,  7.40921681e-02,  8.00096774e-02,\n",
       "        5.28147855e-02,  2.83714611e-02,  4.16008599e-02,  1.02178771e-01,\n",
       "        7.28540176e-02,  1.83131437e-03,  7.37983336e-02,  4.06660452e-02,\n",
       "        4.26119284e-02,  8.68897578e-03,  2.78485630e-02, -3.81381503e-02,\n",
       "        4.75110718e-02, -3.80581044e-02,  4.95937088e-02,  1.48418411e-02,\n",
       "        4.67519188e-02,  7.28465158e-02,  1.17698488e-01,  4.72247701e-02,\n",
       "        2.06683907e-02,  3.16810969e-02,  8.58705513e-02,  5.05774166e-02,\n",
       "        5.66282857e-02,  6.73025455e-02,  1.65470200e-02,  9.30467296e-02,\n",
       "       -3.08570489e-02,  6.07310521e-02,  5.24336724e-02,  1.83595331e-03,\n",
       "       -3.81091342e-02,  9.43412155e-02,  1.28825758e-01,  3.86166331e-02,\n",
       "       -2.40915223e-02,  2.70563223e-02,  4.13901936e-02,  1.24985335e-01,\n",
       "        2.17400394e-03,  1.87087134e-02,  8.10569998e-02,  1.46561710e-02,\n",
       "        4.64143933e-02, -2.91455756e-03,  8.73708377e-02,  3.08221064e-02,\n",
       "        8.87845026e-02, -1.75552507e-02, -9.26679162e-03,  1.62085387e-02,\n",
       "        4.44683290e-02,  1.54839246e-02, -3.81427962e-02,  6.89146696e-02,\n",
       "        6.54348147e-02,  4.28787670e-02,  2.51350395e-02, -3.57470894e-02,\n",
       "        6.79229633e-02,  3.21782667e-02,  2.88958001e-02,  5.63155107e-02,\n",
       "        2.60382540e-02,  1.38618861e-01,  1.33113758e-02,  1.06135797e-01,\n",
       "        9.20455065e-03,  7.90036351e-02, -1.76510541e-02, -3.47985077e-02,\n",
       "        5.52415080e-02,  8.44376600e-03,  2.75732733e-02,  8.66664524e-02,\n",
       "        1.24734456e-02,  2.64963916e-02,  2.99869480e-02,  3.49152551e-02,\n",
       "        1.99442953e-02,  1.34854241e-01,  9.21324514e-02,  7.40237421e-02,\n",
       "        9.89881719e-02, -3.80804802e-02,  6.47643525e-04,  8.55346761e-03,\n",
       "       -2.43950288e-02, -8.51367618e-03,  8.06391076e-02,  5.31547891e-02,\n",
       "       -3.80990224e-02,  2.64627063e-02, -2.37535700e-02, -1.57696534e-02,\n",
       "       -2.58171680e-02,  1.13895252e-01,  7.88052897e-02,  3.16034257e-02,\n",
       "       -2.68598394e-02,  7.46852901e-02,  3.62204037e-02,  6.06483974e-03,\n",
       "        7.67728264e-02,  2.90541768e-02,  7.55830231e-02,  6.75808954e-03,\n",
       "       -3.79984089e-02,  1.21920402e-01,  1.23933915e-01,  1.37800229e-03,\n",
       "        3.09197710e-02,  2.57618674e-02, -3.80976669e-02, -2.28749508e-02,\n",
       "        7.72825654e-02, -2.77952465e-02, -2.47157424e-03,  1.01966736e-01,\n",
       "        1.55213569e-01,  6.40166229e-02,  9.38438465e-02,  3.91051397e-02,\n",
       "        2.80110864e-02, -3.55179734e-03,  1.05974050e-01,  4.16317515e-02,\n",
       "        5.90269518e-02,  2.98199340e-02,  9.95461367e-03,  6.13502852e-02,\n",
       "        7.63410948e-02, -8.73552781e-03,  3.35999765e-02,  1.48872228e-01,\n",
       "       -1.44110873e-02,  9.94897729e-02,  6.76163966e-02, -3.79101111e-02,\n",
       "        7.39082105e-02,  9.93144811e-02, -6.97779930e-03,  7.57922641e-02,\n",
       "        1.82120351e-02,  9.55439424e-02,  7.45263571e-02,  8.02072260e-02,\n",
       "        7.13453241e-02,  9.54244633e-02,  4.03746009e-02, -8.45958428e-03,\n",
       "        5.11850660e-02,  9.33089793e-02,  9.93569356e-02,  1.23351968e-01,\n",
       "       -3.81192848e-02,  3.32792807e-02,  6.52127380e-02,  6.04867341e-02,\n",
       "        6.03615641e-02,  4.79246027e-02,  5.55910415e-02,  1.07909969e-01,\n",
       "        7.05424127e-02,  1.32344519e-01,  9.24014694e-03,  5.73202803e-02,\n",
       "        7.59863154e-02, -3.81148407e-02,  3.77103662e-02,  6.87517219e-02,\n",
       "        4.59139978e-02, -3.81308556e-02,  6.43570198e-02,  2.96526483e-02,\n",
       "        6.62917487e-02,  9.86605797e-02, -5.52893651e-03, -3.13688367e-02,\n",
       "       -3.81202497e-02,  4.66891838e-02,  1.84361049e-02,  1.00155418e-02,\n",
       "       -1.30214008e-02,  5.60482788e-02, -1.29042641e-02,  3.45382214e-02,\n",
       "       -3.48330052e-02,  2.91895699e-02,  4.33716498e-03,  4.37468139e-02,\n",
       "        1.03446509e-01,  1.74432356e-01, -3.40935481e-02,  9.68278224e-02,\n",
       "        4.32608553e-02,  1.23223173e-03,  5.46089400e-03,  1.08593039e-01,\n",
       "        6.83632365e-02,  1.13672684e-01,  7.79830861e-02,  9.62963077e-02,\n",
       "       -6.16265243e-03,  3.10862211e-02,  3.85068933e-02,  6.82117380e-02,\n",
       "        4.88973580e-02,  2.67769402e-02, -3.80828523e-02, -2.93799712e-02,\n",
       "       -3.80220315e-02,  2.36245430e-02,  1.52068849e-01,  1.59586074e-02,\n",
       "        1.83724063e-02,  4.71936820e-02, -2.02656132e-02,  2.31222074e-02,\n",
       "        2.82790038e-02,  1.40920750e-01,  9.80117278e-02,  3.44031569e-02,\n",
       "        5.54929190e-02,  3.97984173e-02, -3.45956742e-02,  1.06489226e-01,\n",
       "        7.36568564e-02,  5.38780891e-02, -3.79870554e-02, -1.80790607e-02,\n",
       "        5.23758161e-02,  2.74025110e-02,  1.85265575e-02,  1.78142643e-02,\n",
       "       -3.48543049e-02, -2.45999343e-02,  8.41675840e-02,  8.24607831e-02,\n",
       "        5.63383573e-02,  1.26944835e-01,  4.95885196e-02,  8.04093533e-02,\n",
       "        4.55061760e-03, -3.61222606e-02,  8.34637885e-02,  1.03194659e-01,\n",
       "        4.18946789e-02,  7.29561289e-02,  4.61785911e-02, -8.28165843e-03])"
      ]
     },
     "execution_count": 31,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "output.clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CorEx with 256 latent factors\n"
     ]
    }
   ],
   "source": [
    "# Do the same for sequences\n",
    "output_sequences = lc.Corex(n_hidden=256, verbose=True, gaussianize='outliers')"
=======
    "dict_prot['LCK']"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2967 iterations to tol: 0.000010, TC=276.838501\n",
      "Warning: step size becoming too small\n",
      "2672 iterations to tol: 0.000010, TC=470.586624\n",
      "Warning: step size becoming too small\n",
      "1567 iterations to tol: 0.000010, TC=568.299149\n",
      "Warning: step size becoming too small\n",
      "900 iterations to tol: 0.000010, TC=609.743561\n",
      "Warning: step size becoming too small\n",
      "525 iterations to tol: 0.000010, TC=625.711395\n",
      "Warning: step size becoming too small\n",
      "458 iterations to tol: 0.000010, TC=631.710144\n",
      "Warning: step size becoming too small\n",
      "133 iterations to tol: 0.000010, TC=635.068817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<linearcorex.linearcorex.Corex at 0x7f8c1484e510>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequences.fit(sequences)"
=======
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/seq_go_prot_embs.pkl', 'wb') as handle:\n",
    "    pickle.dump(dict_prot, handle, protocol=pickle.HIGHEST_PROTOCOL)"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.421,  0.691, -0.4  , ..., -0.94 ,  0.348,  0.199],\n",
       "       [-1.511,  1.135,  0.809, ...,  0.07 , -0.417, -0.386],\n",
       "       [ 0.84 , -0.676, -0.828, ...,  0.613, -0.423, -0.132],\n",
       "       ...,\n",
       "       [-2.081,  0.419,  2.04 , ...,  0.67 ,  0.604,  0.272],\n",
       "       [-2.12 ,  0.888,  1.175, ...,  0.41 ,  0.04 , -0.428],\n",
       "       [-1.705,  0.901,  1.39 , ..., -1.154, -0.154,  0.906]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_lc = output_sequences.transform(sequences)\n",
    "seqs_lc"
=======
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/prot_embs_w_go.pickle', 'rb') as p:\n",
    "    prot_dict = pickle.load(p) "
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.421,  0.691, -0.4  , ...,  4.448,  0.696, -0.84 ],\n",
       "       [-1.511,  1.135,  0.809, ..., -0.322,  1.162,  2.373],\n",
       "       [ 0.84 , -0.676, -0.828, ..., -1.   , -0.817,  0.915],\n",
       "       ...,\n",
       "       [-2.081,  0.419,  2.04 , ...,  0.349, -0.553, -0.434],\n",
       "       [-2.12 ,  0.888,  1.175, ..., -0.399,  0.042, -0.622],\n",
       "       [-1.705,  0.901,  1.39 , ..., -0.269,  0.049,  2.927]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_together_lc = np.hstack((seqs_lc, tots_lc))\n",
    "all_together_lc"
=======
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/seq_go_prot_embs.pkl', 'rb') as p:\n",
    "    prot_dict_new = pickle.load(p) "
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 136,
=======
   "execution_count": 35,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([[-0.424,  0.695, -0.403, ...,  4.841,  0.754, -0.898],\n",
       "       [-1.521,  1.142,  0.814, ..., -0.345,  1.266,  2.544],\n",
       "       [ 0.844, -0.681, -0.833, ..., -1.081, -0.909,  0.982],\n",
       "       ...,\n",
       "       [-2.095,  0.422,  2.054, ...,  0.385, -0.619, -0.462],\n",
       "       [-2.133,  0.894,  1.183, ..., -0.428,  0.035, -0.664],\n",
       "       [-1.716,  0.907,  1.399, ..., -0.287,  0.043,  3.138]])"
      ]
     },
     "execution_count": 136,
=======
       "array([ 6.80741737e-04, -5.20140186e-03, -4.91125616e-03, -7.13793314e-03,\n",
       "        2.60472890e-03, -4.94904897e-03, -4.01444793e-03,  4.03560309e-03,\n",
       "        9.37388638e-04,  1.40363649e-03, -6.13986984e-03,  4.78779666e-03,\n",
       "        1.61745967e-03,  6.40811102e-04, -6.73815890e-03, -4.66001559e-03,\n",
       "        2.49348127e-04,  2.50794964e-03,  5.72694868e-04, -2.91368613e-03,\n",
       "        3.84578379e-03, -3.28111180e-03,  4.07867394e-03,  1.41839305e-03,\n",
       "        1.77334747e-02,  4.73109338e-06,  5.49182629e-03, -3.53519591e-03,\n",
       "        6.83443761e-03,  2.01057383e-04,  1.47041768e-02, -4.43995079e-03,\n",
       "        3.31080599e-03,  3.38244188e-03,  4.29012825e-03, -2.62126097e-03,\n",
       "        3.78287608e-03,  7.25703195e-03,  1.10038558e-03,  6.64741820e-04,\n",
       "        1.57246262e-03, -8.52159761e-03, -2.43478010e-03, -2.19094682e-03,\n",
       "       -3.18241669e-03, -6.97733174e-03,  2.68247417e-03,  1.76729385e-03,\n",
       "       -3.00141515e-03,  5.51224713e-03, -4.79580830e-03,  3.80675417e-03,\n",
       "        9.35875232e-03,  5.86788516e-04,  7.05225772e-03, -2.72020328e-03,\n",
       "       -4.78526483e-03,  5.04949210e-03, -4.10635883e-04, -2.21582358e-03,\n",
       "       -3.39165574e-03, -6.60854266e-04,  1.72978381e-03,  1.55540495e-03,\n",
       "       -4.86803568e-04,  1.89179162e-03,  1.43267363e-03,  2.42218174e-03,\n",
       "       -8.57320489e-03, -2.29762576e-03, -6.50176486e-04,  3.45806145e-03,\n",
       "        3.40013235e-03, -5.72261014e-03,  3.28323815e-03,  1.22445941e-02,\n",
       "        4.21351374e-03, -6.54625012e-03,  8.98190229e-03, -3.68432939e-03,\n",
       "        1.45863669e-03, -4.04920642e-03,  7.77035824e-03,  4.22817280e-03,\n",
       "        1.98437315e-03,  1.16173903e-03, -7.73558100e-04, -6.23177218e-04,\n",
       "        2.23179804e-03,  2.25242113e-03, -2.22296202e-03, -7.47587965e-03,\n",
       "        3.35161177e-03,  6.51382912e-03,  2.11276164e-03, -8.67988124e-03,\n",
       "       -2.35953465e-03,  2.22674440e-03,  1.96174351e-03,  6.48372266e-03,\n",
       "       -1.07667417e-03, -1.94053063e-03,  1.87502496e-03, -8.99443662e-03,\n",
       "        6.04439498e-03, -2.58892991e-04,  1.75251870e-03,  7.03968329e-03,\n",
       "       -4.33610828e-03, -1.13105507e-03,  1.57110262e-03,  1.23878588e-02,\n",
       "       -9.26687537e-04,  1.16004204e-02,  1.07479648e-03, -3.69163257e-03,\n",
       "       -3.52573987e-03, -1.91724896e-03, -1.50739008e-03, -7.72031468e-03,\n",
       "       -1.40392379e-03, -4.92659596e-04,  5.22047756e-03, -2.21994144e-03,\n",
       "       -4.01211496e-03, -5.99043112e-03, -2.81257366e-03, -2.70758908e-03,\n",
       "       -3.81137672e-02,  1.08683525e-02,  7.40921681e-02,  8.00096774e-02,\n",
       "        5.28147855e-02,  2.83714611e-02,  4.16008599e-02,  1.02178771e-01,\n",
       "        7.28540176e-02,  1.83131437e-03,  7.37983336e-02,  4.06660452e-02,\n",
       "        4.26119284e-02,  8.68897578e-03,  2.78485630e-02, -3.81381503e-02,\n",
       "        4.75110718e-02, -3.80581044e-02,  4.95937088e-02,  1.48418411e-02,\n",
       "        4.67519188e-02,  7.28465158e-02,  1.17698488e-01,  4.72247701e-02,\n",
       "        2.06683907e-02,  3.16810969e-02,  8.58705513e-02,  5.05774166e-02,\n",
       "        5.66282857e-02,  6.73025455e-02,  1.65470200e-02,  9.30467296e-02,\n",
       "       -3.08570489e-02,  6.07310521e-02,  5.24336724e-02,  1.83595331e-03,\n",
       "       -3.81091342e-02,  9.43412155e-02,  1.28825758e-01,  3.86166331e-02,\n",
       "       -2.40915223e-02,  2.70563223e-02,  4.13901936e-02,  1.24985335e-01,\n",
       "        2.17400394e-03,  1.87087134e-02,  8.10569998e-02,  1.46561710e-02,\n",
       "        4.64143933e-02, -2.91455756e-03,  8.73708377e-02,  3.08221064e-02,\n",
       "        8.87845026e-02, -1.75552507e-02, -9.26679162e-03,  1.62085387e-02,\n",
       "        4.44683290e-02,  1.54839246e-02, -3.81427962e-02,  6.89146696e-02,\n",
       "        6.54348147e-02,  4.28787670e-02,  2.51350395e-02, -3.57470894e-02,\n",
       "        6.79229633e-02,  3.21782667e-02,  2.88958001e-02,  5.63155107e-02,\n",
       "        2.60382540e-02,  1.38618861e-01,  1.33113758e-02,  1.06135797e-01,\n",
       "        9.20455065e-03,  7.90036351e-02, -1.76510541e-02, -3.47985077e-02,\n",
       "        5.52415080e-02,  8.44376600e-03,  2.75732733e-02,  8.66664524e-02,\n",
       "        1.24734456e-02,  2.64963916e-02,  2.99869480e-02,  3.49152551e-02,\n",
       "        1.99442953e-02,  1.34854241e-01,  9.21324514e-02,  7.40237421e-02,\n",
       "        9.89881719e-02, -3.80804802e-02,  6.47643525e-04,  8.55346761e-03,\n",
       "       -2.43950288e-02, -8.51367618e-03,  8.06391076e-02,  5.31547891e-02,\n",
       "       -3.80990224e-02,  2.64627063e-02, -2.37535700e-02, -1.57696534e-02,\n",
       "       -2.58171680e-02,  1.13895252e-01,  7.88052897e-02,  3.16034257e-02,\n",
       "       -2.68598394e-02,  7.46852901e-02,  3.62204037e-02,  6.06483974e-03,\n",
       "        7.67728264e-02,  2.90541768e-02,  7.55830231e-02,  6.75808954e-03,\n",
       "       -3.79984089e-02,  1.21920402e-01,  1.23933915e-01,  1.37800229e-03,\n",
       "        3.09197710e-02,  2.57618674e-02, -3.80976669e-02, -2.28749508e-02,\n",
       "        7.72825654e-02, -2.77952465e-02, -2.47157424e-03,  1.01966736e-01,\n",
       "        1.55213569e-01,  6.40166229e-02,  9.38438465e-02,  3.91051397e-02,\n",
       "        2.80110864e-02, -3.55179734e-03,  1.05974050e-01,  4.16317515e-02,\n",
       "        5.90269518e-02,  2.98199340e-02,  9.95461367e-03,  6.13502852e-02,\n",
       "        7.63410948e-02, -8.73552781e-03,  3.35999765e-02,  1.48872228e-01,\n",
       "       -1.44110873e-02,  9.94897729e-02,  6.76163966e-02, -3.79101111e-02,\n",
       "        7.39082105e-02,  9.93144811e-02, -6.97779930e-03,  7.57922641e-02,\n",
       "        1.82120351e-02,  9.55439424e-02,  7.45263571e-02,  8.02072260e-02,\n",
       "        7.13453241e-02,  9.54244633e-02,  4.03746009e-02, -8.45958428e-03,\n",
       "        5.11850660e-02,  9.33089793e-02,  9.93569356e-02,  1.23351968e-01,\n",
       "       -3.81192848e-02,  3.32792807e-02,  6.52127380e-02,  6.04867341e-02,\n",
       "        6.03615641e-02,  4.79246027e-02,  5.55910415e-02,  1.07909969e-01,\n",
       "        7.05424127e-02,  1.32344519e-01,  9.24014694e-03,  5.73202803e-02,\n",
       "        7.59863154e-02, -3.81148407e-02,  3.77103662e-02,  6.87517219e-02,\n",
       "        4.59139978e-02, -3.81308556e-02,  6.43570198e-02,  2.96526483e-02,\n",
       "        6.62917487e-02,  9.86605797e-02, -5.52893651e-03, -3.13688367e-02,\n",
       "       -3.81202497e-02,  4.66891838e-02,  1.84361049e-02,  1.00155418e-02,\n",
       "       -1.30214008e-02,  5.60482788e-02, -1.29042641e-02,  3.45382214e-02,\n",
       "       -3.48330052e-02,  2.91895699e-02,  4.33716498e-03,  4.37468139e-02,\n",
       "        1.03446509e-01,  1.74432356e-01, -3.40935481e-02,  9.68278224e-02,\n",
       "        4.32608553e-02,  1.23223173e-03,  5.46089400e-03,  1.08593039e-01,\n",
       "        6.83632365e-02,  1.13672684e-01,  7.79830861e-02,  9.62963077e-02,\n",
       "       -6.16265243e-03,  3.10862211e-02,  3.85068933e-02,  6.82117380e-02,\n",
       "        4.88973580e-02,  2.67769402e-02, -3.80828523e-02, -2.93799712e-02,\n",
       "       -3.80220315e-02,  2.36245430e-02,  1.52068849e-01,  1.59586074e-02,\n",
       "        1.83724063e-02,  4.71936820e-02, -2.02656132e-02,  2.31222074e-02,\n",
       "        2.82790038e-02,  1.40920750e-01,  9.80117278e-02,  3.44031569e-02,\n",
       "        5.54929190e-02,  3.97984173e-02, -3.45956742e-02,  1.06489226e-01,\n",
       "        7.36568564e-02,  5.38780891e-02, -3.79870554e-02, -1.80790607e-02,\n",
       "        5.23758161e-02,  2.74025110e-02,  1.85265575e-02,  1.78142643e-02,\n",
       "       -3.48543049e-02, -2.45999343e-02,  8.41675840e-02,  8.24607831e-02,\n",
       "        5.63383573e-02,  1.26944835e-01,  4.95885196e-02,  8.04093533e-02,\n",
       "        4.55061760e-03, -3.61222606e-02,  8.34637885e-02,  1.03194659e-01,\n",
       "        4.18946789e-02,  7.29561289e-02,  4.61785911e-02, -8.28165843e-03])"
      ]
     },
     "execution_count": 35,
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "scaler = StandardScaler()\n",
    "atlc = scaler.fit_transform(all_together_lc)\n",
    "atlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_dict = {}\n",
    "for n, val in zip(names, all_together_lc):\n",
    "    prot_dict[n] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/rootlocus/Desktop/NTUA/Systems_Biology_Lab/DiplomaThesis/SNAC/data/lc_embeddings_raw.pkl', 'wb') as f:\n",
    "    pickle.dump(prot_dict, f)"
=======
    "prot_dict_new['LCK']"
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit88de374606404c929f8e9f33cc867e5f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
=======
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
>>>>>>> a2efbcf6c7155c393fe4a9f4f4e38666a3083097
}
