{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import functools\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, roc_curve, roc_auc_score, \\\n",
    "    auc, average_precision_score, pairwise_distances\n",
    "import scikitplot as skplt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgb_hyper import objective\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pickle\n",
    "import dill\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read gene features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(\"data/gene_data/gene_features_all.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the training,val,test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(\"data/gene_data/allsigs.csv\",index_col=0)\n",
    "val1_df = pd.read_csv(\"data/gene_data/splits/csv/val_set_1.csv\",index_col=0)\n",
    "val2_df = pd.read_csv(\"data/gene_data/splits/csv/val_set_2.csv\",index_col=0)\n",
    "val3_df = pd.read_csv(\"data/gene_data/splits/csv/val_set_3.csv\",index_col=0)\n",
    "val4_df = pd.read_csv(\"data/gene_data/splits/csv/val_set_4.csv\",index_col=0)\n",
    "test_df = pd.read_csv(\"data/gene_data/splits/csv/test_set.csv\",index_col=0)\n",
    "\n",
    "valsets = [val1_df,val2_df,val3_df,val4_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only keep labels with more than 3 examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = all_df[all_df[\"moa_count\"]>3]\n",
    "genes = genes.loc[all_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# turn labels to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(all_df.moa_v1)\n",
    "all_df['moa_categorical'] = le.transform(all_df.moa_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first remove the test set from all_df and all genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_genes = genes.loc[test_df[\"sig_id\"]]\n",
    "test_sigs = all_df.loc[test_df[\"sig_id\"]]\n",
    "all_df = all_df.drop(test_df[\"sig_id\"])\n",
    "genes = genes.drop(test_df[\"sig_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the space\n",
    "fspace = {\n",
    "    'colsample_bylevel' : hp.uniform('colsample_bylevel', 0.1, 1), #+\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.1, 1), #+\n",
    "    'gamma' : hp.uniform('gamma', 0.1, 1), #+\n",
    "    'learning_rate' : hp.uniform('learning_rate', 0.1, 1),\n",
    "    'max_delta_step' : hp.quniform('max_delta_step',1,10,1),\n",
    "    'max_depth' : hp.quniform('max_depth',6, 12, 1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight',10 ,500 ,5),\n",
    "    'reg_alpha' : hp.uniform('reg_alpha',0.1,100),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda',0.1,100),\n",
    "    'subsample' : hp.uniform('subsample',0.1,1.0),\n",
    "    'max_bin' : hp.quniform('max_bin',16,256,16)\n",
    "    # add sampling method,max bin,predicto,monotone_constraints,interaction_constraints,single_precision_histogram\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(fspace, all_df, genes, valsets):\n",
    "    accs = []\n",
    "    model_params = {\n",
    "        \"colsample_bylevel\" : fspace['colsample_bylevel'],\n",
    "        \"colsample_bytree\" : fspace['colsample_bytree'],\n",
    "        \"gamma\" : fspace['gamma'],\n",
    "        \"eta\" : fspace['learning_rate'],\n",
    "        \"max_delta_step\" : int(fspace['max_delta_step']),\n",
    "        \"max_depth\" : int(fspace['max_depth']),\n",
    "        \"min_child_weight\" : int(fspace['min_child_weight']),\n",
    "        \"alpha\" : fspace['reg_alpha'],\n",
    "        \"lambda\" : fspace['reg_lambda'],\n",
    "        \"subsample\" : fspace['subsample'],\n",
    "        \"objective\":'multi:softmax',\n",
    "        'num_class': all_df['moa_categorical'].nunique(),\n",
    "        \"booster\":'gbtree',\n",
    "        \"eval_metric\":'merror'\n",
    "        }\n",
    "    for i in range(len(valsets)):\n",
    "        val_genes = genes.loc[valsets[i][\"sig_id\"]]\n",
    "        val_sigs = all_df.loc[valsets[i][\"sig_id\"]]\n",
    "        train_genes = genes.drop(valsets[i][\"sig_id\"])\n",
    "        train_sigs = all_df.drop(valsets[i][\"sig_id\"])\n",
    "        dtrain = xgb.DMatrix(data=train_genes, label=train_sigs['moa_categorical'])\n",
    "        dtest = xgb.DMatrix(data=val_genes, label = val_sigs['moa_categorical'])\n",
    "        evalist = [(dtest,'eval'),(dtrain,'train')]\n",
    "        bst = xgb.train(model_params, dtrain, 100, evalist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "        pred = bst.predict(dtest)\n",
    "        accs.append(accuracy_score(val_sigs['moa_categorical'], pred))\n",
    "    ave_acc = np.mean(accs,axis = 0)\n",
    "    return {'loss': -ave_acc ,  'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin_objective = partial(objective, all_df = all_df, genes = genes, valsets = valsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 1000  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"my_model.hyperopt\", \"rb\"))\n",
    "        print(\"Found saved Trials! Loading...\")\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn = fmin_objective, space = fspace, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "    print(\"Best:\", best)\n",
    "    \n",
    "    # save the trials object\n",
    "    with open(\"my_model.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "    return(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved Trials! Loading...\n",
      "Rerunning from 21 trials to 1021 (+1000) trials\n",
      "100%|█████████████████████████████████████████| 1021/1021 [8:14:38<00:00, 29.07s/trial, best loss: -0.6027980422938406]\n",
      "Best: {'colsample_bylevel': 0.35788804057451146, 'colsample_bytree': 0.1226530432425497, 'gamma': 0.1571640395272282, 'learning_rate': 0.8098321148828739, 'max_bin': 176.0, 'max_delta_step': 5.0, 'max_depth': 11.0, 'min_child_weight': 10.0, 'reg_alpha': 2.0041642106706092, 'reg_lambda': 69.63017517747672, 'subsample': 0.7429682334802664}\n"
     ]
    }
   ],
   "source": [
    "trials = run_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = trials.trials[index]['misc']['vals']\n",
    "hyper_params = {\n",
    "        \"colsample_bylevel\" : 0.35788804057451146,\n",
    "        \"colsample_bytree\" : 0.1226530432425497,\n",
    "        \"gamma\" : 0.1571640395272282,\n",
    "        \"eta\" : 0.8098321148828739,\n",
    "        \"max_delta_step\" : 5,\n",
    "        \"max_depth\" : 11,\n",
    "        \"min_child_weight\" : 10,\n",
    "        \"alpha\" : 2.0041642106706092,\n",
    "        \"lambda\" : 69.63017517747672,\n",
    "        \"subsample\" : 0.7429682334802664,\n",
    "        \"objective\":'multi:softmax',\n",
    "        'num_class': all_df['moa_categorical'].nunique(),\n",
    "        \"booster\":'gbtree',\n",
    "        \"eval_metric\":'merror'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for i in range(len(valsets)):\n",
    "    val_genes = genes.loc[valsets[i][\"sig_id\"]]\n",
    "    val_sigs = all_df.loc[valsets[i][\"sig_id\"]]\n",
    "    train_genes = genes.drop(valsets[i][\"sig_id\"])\n",
    "    train_sigs = all_df.drop(valsets[i][\"sig_id\"])\n",
    "    dtrain = xgb.DMatrix(data=train_genes, label=train_sigs['moa_categorical'])\n",
    "    dtest = xgb.DMatrix(data=val_genes, label = val_sigs['moa_categorical'])\n",
    "    evalist = [(dtest,'eval'),(dtrain,'train')]\n",
    "    bst = xgb.train(hyper_params, dtrain, 100, evalist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "    pred = bst.predict(dtest)\n",
    "    accs.append(accuracy_score(val_sigs['moa_categorical'], pred))\n",
    "ave_acc = np.mean(accs,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6554621848739496,\n",
       " 0.5076923076923077,\n",
       " 0.6326530612244898,\n",
       " 0.6153846153846154]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46153846153846156\n"
     ]
    }
   ],
   "source": [
    "val_genes = genes.loc[valsets[0][\"sig_id\"]]\n",
    "val_sigs = all_df.loc[valsets[0][\"sig_id\"]]\n",
    "train_genes = genes.drop(valsets[0][\"sig_id\"])\n",
    "train_sigs = all_df.drop(valsets[0][\"sig_id\"])\n",
    "dtrain = xgb.DMatrix(data=train_genes, label=train_sigs['moa_categorical'])\n",
    "dval = xgb.DMatrix(data=val_genes, label = val_sigs['moa_categorical'])\n",
    "dtest = xgb.DMatrix(data=test_genes)\n",
    "evalist = [(dval,'eval'),(dtrain,'train')]\n",
    "bst = xgb.train(hyper_params, dtrain, 100, evalist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "pred = bst.predict(dtest)\n",
    "print(accuracy_score(test_sigs['moa_categorical'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le.inverse_transform(pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
